{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TffNbYWMzw7Z"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "from PIL import Image\n",
        "from multiprocessing import Queue\n",
        "import numpy as np\n",
        "import threading\n",
        "#from cStringIO import StringIO\n",
        "import io\n",
        "from io import StringIO\n",
        "import tensorflow as tf\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zml4ZH8KgSk7",
        "outputId": "afcdea59-b7e7-47a4-b811-4ec78e3e5633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#workdir = '/content/drive/MyDrive/dataset_ml/amazon_men_actualizado/' #mario\n",
        "workdir = '/content/drive/MyDrive/amazon_men_actualizado/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qQeAQpkcuID"
      },
      "outputs": [],
      "source": [
        "user_train = np.load(workdir + 'dic_train_men.npy',allow_pickle='TRUE')\n",
        "user_train=list(user_train.reshape(-1,1))[0][0]\n",
        "\n",
        "user_test = np.load(workdir + 'dic_test_men.npy',allow_pickle='TRUE')\n",
        "user_test=list(user_test.reshape(-1,1))[0][0]\n",
        "\n",
        "Item = np.load(workdir + 'items_men.npy',allow_pickle='TRUE')\n",
        "Item=list(Item.reshape(-1,1))[0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lr08_tJ_KhE"
      },
      "outputs": [],
      "source": [
        "#Hyper-prameters\n",
        "K = 100 # Latent dimensionality\n",
        "lambda1 = 0.001 # Weight decay\n",
        "lambda2 = 0.1 # Regularizer for theta_u\n",
        "learning_rate = 0.1\n",
        "training_epoch = 600\n",
        "batch_size = 128 #4000\n",
        "dropout = 0.5 # Dropout, probability to keep units\n",
        "numldprocess=4 # multi-threading for loading images\n",
        "usernum = len(user_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py3OfQVwgpBF"
      },
      "outputs": [],
      "source": [
        "set_im = []\n",
        "\n",
        "for user in user_train:\n",
        "  for item in range(len(user_train[user])):\n",
        "    if user_train[user][item][b'productid'] not in set_im:\n",
        "      set_im.append(user_train[user][item][b'productid'])\n",
        "itemnum= len(set_im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zneRIBe2SMz"
      },
      "outputs": [],
      "source": [
        "# Create some wrappers for simplicity\n",
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
        "                          padding='SAME')\n",
        "\n",
        "def avgpool2d(x, k=2):\n",
        "    return tf.nn.avg_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
        "                          padding='SAME')\n",
        "\n",
        "weights = {\n",
        "    'wc1': [11, 11, 3, 64],\n",
        "    'wc2': [5, 5, 64, 256],\n",
        "    'wc3': [3, 3, 256, 256],\n",
        "    'wc4': [3, 3, 256, 256],\n",
        "    'wc5': [3, 3, 256, 256],    \n",
        "    'wd1': [7*7*256, 4096],\n",
        "    'wd2': [4096, 4096],\n",
        "    'wd3': [4096, K],\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'bc1': [64],\n",
        "    'bc2': [256],\n",
        "    'bc3': [256],\n",
        "    'bc4': [256],\n",
        "    'bc5': [256],\n",
        "    'bd1': [4096],\n",
        "    'bd2': [4096],\n",
        "    'bd3': [K],\n",
        "}\n",
        "\n",
        "def Weights(name):\n",
        "    return tf.compat.v1.get_variable(name,dtype=tf.float32,shape=weights[name],initializer=tf.compat.v1.keras.initializers.glorot_normal())\n",
        "\n",
        "def Biases(name):\n",
        "    return tf.compat.v1.get_variable(name,dtype=tf.float32,initializer=tf.zeros(biases[name]))\n",
        "       \n",
        "# Create CNN model\n",
        "def CNN(x,dropout):\n",
        "    # Reshape input picture\n",
        "    x = tf.reshape(x, shape=[-1, 224, 224, 3])\n",
        "\n",
        "\n",
        "    conv1 = conv2d(x, Weights('wc1'), Biases('bc1'), strides=4)\n",
        "    conv1 = tf.nn.relu(conv1)\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "    \n",
        "    conv2 = conv2d(conv1, Weights('wc2'), Biases('bc2'))\n",
        "    conv2 = tf.nn.relu(conv2)\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "    \n",
        "    conv3 = conv2d(conv2, Weights('wc3'), Biases('bc3'))\n",
        "    conv3 = tf.nn.relu(conv3)\n",
        "    \n",
        "    conv4 = conv2d(conv3, Weights('wc4'), Biases('bc4'))\n",
        "    conv4 = tf.nn.relu(conv4)\n",
        "    \n",
        "    conv5 = conv2d(conv4, Weights('wc5'), Biases('bc5'))\n",
        "    conv5 = tf.nn.relu(conv5)\n",
        "    conv5 = maxpool2d(conv5, k=2)\n",
        "\n",
        "    fc1 = tf.reshape(conv5, [-1,weights['wd1'][0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1, Weights('wd1')), Biases('bd1'))\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    fc1 = tf.nn.dropout(fc1, dropout)\n",
        "    \n",
        "    fc2 = tf.add(tf.matmul(fc1, Weights('wd2')), Biases('bd2'))\n",
        "    fc2 = tf.nn.relu(fc2)\n",
        "    fc2 = tf.nn.dropout(fc2, dropout)\n",
        "    \n",
        "    fc3 = tf.add(tf.matmul(fc2, Weights('wd3')), Biases('bd3'))\n",
        "    \n",
        "    return fc3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y76eX6W45cbP"
      },
      "outputs": [],
      "source": [
        "#define model\n",
        "tf.compat.v1.reset_default_graph()\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "with tf.device('/gpu:0'):\n",
        "    #training sample\n",
        "    queueu = tf.compat.v1.placeholder(dtype=tf.int32,shape=[1])\n",
        "    queuei = tf.compat.v1.placeholder(dtype=tf.int32,shape=[1])\n",
        "    queuej = tf.compat.v1.placeholder(dtype=tf.int32,shape=[1])\n",
        "    queueimage1 = tf.compat.v1.placeholder(dtype=tf.uint8,shape=[224,224,3])\n",
        "    queueimage2 = tf.compat.v1.placeholder(dtype=tf.uint8,shape=[224,224,3])\n",
        "    batch_train_queue = tf.compat.v1.FIFOQueue(batch_size*5, dtypes=[tf.int32,tf.int32,tf.int32,tf.uint8,tf.uint8], shapes=[[1],[1],[1],[224,224,3],[224,224,3]])\n",
        "    batch_train_queue_op = batch_train_queue.enqueue([queueu,queuei,queuej,queueimage1,queueimage2]);\n",
        "    u,i,j,image1,image2 = batch_train_queue.dequeue_many(batch_size)\n",
        "\n",
        "    image_test=tf.compat.v1.placeholder(dtype=tf.uint8,shape=[batch_size,224,224,3])\n",
        "    \n",
        "    image1=(tf.compat.v1.to_float(image1)-127.5)/127.5\n",
        "    image2=(tf.compat.v1.to_float(image2)-127.5)/127.5\n",
        "    _image_test=(tf.compat.v1.to_float(image_test)-127.5)/127.5\n",
        "\n",
        "    u=tf.reshape(u,shape=[batch_size])\n",
        "    i=tf.reshape(i,shape=[batch_size])\n",
        "    j=tf.reshape(j,shape=[batch_size])\n",
        "    \n",
        "    keep_prob = tf.compat.v1.placeholder(tf.float32) #dropout (keep probability)\n",
        "\n",
        "    #siamese networks\n",
        "    with tf.compat.v1.variable_scope(\"DVBPR\") as scope:\n",
        "        result1 = CNN(image1,dropout) #primera cnn\n",
        "        scope.reuse_variables() #pesos compartidos\n",
        "        result2 = CNN(image2,dropout) #segunda cnn\n",
        "        result_test = CNN(_image_test, 0.99) #dropout 1?\n",
        "        nn_regularizers = sum(map(tf.nn.l2_loss,[Weights('wd1'), Weights('wd2'), Weights('wd3'), Weights('wc1'), Weights('wc2'), Weights('wc3'), Weights('wc4'), Weights('wc5')]))\n",
        "        thetau = tf.Variable(tf.compat.v1.random_uniform([usernum,K],minval=0,maxval=1)/100)\n",
        "   #loss\n",
        "    cost_train = tf.reduce_sum(tf.compat.v1.log(tf.sigmoid(tf.reduce_sum(tf.multiply(tf.gather(thetau,u),tf.subtract(result1,result2)),1,keepdims=True))))\n",
        "    regularizers = tf.nn.l2_loss(tf.gather(thetau,u))\n",
        "    cost_train -= lambda1 * nn_regularizers + lambda2 * regularizers #regulariza pesos y norma de la representacion\n",
        "    optimizer =  tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(-cost_train)  #adam\n",
        "    \n",
        "# Initializing the variables\n",
        "init = tf.compat.v1.initialize_all_variables()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnKCoi_y5lAD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def AUC(user_train, user_test, U, I):\n",
        "  \"\"\"\n",
        "  para cada usuario cuenta cuantos items de una muestra aleatoria tiene rating menor a \n",
        "  al rating del item consumido en test\n",
        "  \"\"\"\n",
        "  ans=0\n",
        "  cc=0\n",
        "\n",
        "  for user in user_test:\n",
        "      item_test= user_test[user][0][b'productid']\n",
        "      if item_test in set_im: #esta en train....\n",
        "        item_test= set_im.index(item_test)\n",
        "        T=np.dot(U[list(user_test.keys()).index(user),:],I.T)\n",
        "        cc+=1\n",
        "        no_considerar= set([set_im.index(user_train[user][item][b'productid']) for item in range(len(user_train[user]))]+ [item_test]) \n",
        "        count=0\n",
        "        tmpans=0\n",
        "\n",
        "        for j in random.sample(set_im,int(50*(len(no_considerar)-1))): #sample\n",
        "            j= set_im.index(j)\n",
        "            if j in no_considerar: continue\n",
        "            if T[item_test] > T[j]:\n",
        "              tmpans+=1\n",
        "            count +=1\n",
        "\n",
        "        tmpans/=float(count)\n",
        "        ans+=tmpans\n",
        "  \n",
        "  ans/=float(cc)\n",
        "  return ans\n",
        "\n",
        "def Evaluation(step): #para cada epoca???? \n",
        "    print ('...')\n",
        "    U=sess.run(thetau) #representacion visual del usuario\n",
        "    I=np.zeros([itemnum,K],dtype=np.float32) #matriz para guardar todas las representaciones de las imagenes en K dim\n",
        "    idx=np.array_split(range(itemnum),(itemnum+batch_size-1)/batch_size) #np.array_split(range(itemnum),5)\n",
        "    \n",
        "    input_images=np.zeros([batch_size,224,224,3],dtype=np.int8)\n",
        "    for i in range(len(idx)): \n",
        "        print(\"minibatch: \", i,\"/\",len(idx))\n",
        "        cc=0\n",
        "        for j in idx[i]: #para cada elemento del minibatch i\n",
        "             #accedo a los indices de imagenes que corresponden\n",
        "            img_ = PIL.Image.open(io.BytesIO(Item[ set_im[j]][b'imgs']))\n",
        "            input_images[cc]=np.uint8(np.asarray( img_.convert('RGB').resize((224,224)))) #guarda la imagen\n",
        "            cc+=1\n",
        "        #en cada minibatch ejecuta y guarda\n",
        "        I[idx[i][0]:(idx[i][-1]+1)]=sess.run(result_test,feed_dict={image_test:input_images})[:(idx[i][-1]-idx[i][0]+1)]\n",
        "    print ('export finised! lei las imagenes')\n",
        "    np.save('UI_'+str(K)+'_'+str(step)+'.npy',[U,I])\n",
        "    return AUC(user_train,user_train,U,I), AUC(user_train,user_test,U,I) #train, test\n",
        "\n",
        "def sample(user):\n",
        "    u = random.choice(list(user.keys()))#user id random\n",
        "    numu = len(user[u]) # cantidad de items consumidos por ese usuario\n",
        "    i = set_im.index(user[u][random.randrange(numu)][b'productid']) #escoger un producto id al azar de esos\n",
        "    M=set()\n",
        "    for item in user[u]:\n",
        "        M.add(set_im.index(item[b'productid'])) #se crea el conjunto M de productos unicos del usuario\n",
        "\n",
        "    while True:\n",
        "        j= set_im.index(random.choice(set_im)) #se escoge un item al azar\n",
        "        if (not j in M): break #si el item no fue consumido por el usuario listo...\n",
        "        \n",
        "    return (u,i,j)\n",
        "\n",
        "\n",
        "def load_image_async(): #carga imagenes\n",
        "    print(\"load_image\")\n",
        "    while True:\n",
        "        (uuu,iii,jjj)=sample(user_train)\n",
        "        #iii_fix= set_im.index(iii)\n",
        "        #jjj_fix= set_im.index(jjj)\n",
        "        #print(\"index: \", iii_fix, \"item\", iii, \"\\n\")\n",
        "        img = PIL.Image.open(io.BytesIO(Item[set_im[iii]][b'imgs']))\n",
        "        jpg1=np.uint8(np.asarray( img.convert('RGB').resize((224,224))))\n",
        "        img_j = PIL.Image.open(io.BytesIO(Item[set_im[jjj]][b'imgs'])) \n",
        "        jpg2=np.uint8(np.asarray( img_j.convert('RGB').resize((224,224))))\n",
        "\n",
        "        sess.run(batch_train_queue_op,feed_dict={queueu:np.asarray([uuu]),\n",
        "                                                 queuei:np.asarray([iii]),\n",
        "                                                 queuej:np.asarray([jjj]),\n",
        "                                                 queueimage1:jpg1,queueimage2:jpg2,\n",
        "                                                })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTCOHQjvAF0D",
        "outputId": "aa43b868-67fc-48bc-e6ce-b18aa36eb2ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load_image\n",
            "load_image\n",
            "load_image\n",
            "load_image\n",
            "inicia train\n",
            "CPU times: user 654 ms, sys: 228 ms, total: 881 ms\n",
            "Wall time: 768 ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1771: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "f=open('DVBPR.log','w')\n",
        "config = tf.compat.v1.ConfigProto(log_device_placement=False,allow_soft_placement=True)\n",
        "sess=tf.compat.v1.Session(config=config)\n",
        "sess.run(init)\n",
        "\n",
        "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
        "session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
        "\n",
        "t=[0]*numldprocess\n",
        "for i in range(numldprocess):\n",
        "    t[i] = threading.Thread(target=load_image_async)\n",
        "    t[i].daemon=True\n",
        "    t[i].start()\n",
        "\n",
        "oneiteration = 0\n",
        "for item in user_train: oneiteration+=len(user_train[item]) # total interacciones\n",
        "\n",
        "step = 1\n",
        "saver = tf.compat.v1.train.Saver([k for k in tf.compat.v1.global_variables() if k.name.startswith('DVBPR')])\n",
        "\n",
        "epoch=0\n",
        "print(\"inicia train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXw2WWl4PhVN",
        "outputId": "3aed82f9-a36a-4241-c56b-c3f0ed271b73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cantidad de epocas convolucionales:  60393\n"
          ]
        }
      ],
      "source": [
        "print(\"cantidad de epocas convolucionales: \",int((training_epoch*oneiteration+1)/batch_size) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B8tT2q_OdsHl",
        "outputId": "836cd3ab-b601-4e49-e82c-5a5f1ec57954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step#1000 CNN update\n",
            "Step#2000 CNN update\n",
            "Step#3000 CNN update\n",
            "Step#4000 CNN update\n",
            "Step#5000 CNN update\n",
            "Step#6000 CNN update\n",
            "Step#7000 CNN update\n",
            "Step#8000 CNN update\n",
            "Step#9000 CNN update\n",
            "Step#10000 CNN update\n",
            "Step#11000 CNN update\n",
            "Step#12000 CNN update\n",
            "Step#13000 CNN update\n",
            "Step#14000 CNN update\n",
            "Step#15000 CNN update\n",
            "Step#16000 CNN update\n",
            "Step#17000 CNN update\n",
            "Step#18000 CNN update\n",
            "Step#19000 CNN update\n",
            "Step#20000 CNN update\n",
            "Step#21000 CNN update\n",
            "Step#22000 CNN update\n",
            "Step#23000 CNN update\n",
            "Step#24000 CNN update\n",
            "Step#25000 CNN update\n",
            "Step#26000 CNN update\n",
            "Step#27000 CNN update\n",
            "Step#28000 CNN update\n",
            "Step#29000 CNN update\n",
            "Step#30000 CNN update\n",
            "Step#31000 CNN update\n",
            "Step#32000 CNN update\n",
            "Step#33000 CNN update\n",
            "Step#34000 CNN update\n",
            "Step#35000 CNN update\n",
            "Step#36000 CNN update\n",
            "Step#37000 CNN update\n",
            "Step#38000 CNN update\n",
            "Step#39000 CNN update\n",
            "Step#40000 CNN update\n",
            "Step#41000 CNN update\n",
            "Step#42000 CNN update\n",
            "Step#43000 CNN update\n",
            "Step#44000 CNN update\n",
            "Step#45000 CNN update\n",
            "Step#46000 CNN update\n",
            "Step#47000 CNN update\n",
            "Step#48000 CNN update\n",
            "Step#49000 CNN update\n",
            "Step#50000 CNN update\n",
            "Step#51000 CNN update\n",
            "Step#52000 CNN update\n",
            "Step#53000 CNN update\n",
            "Step#54000 CNN update\n",
            "Step#55000 CNN update\n",
            "Step#56000 CNN update\n",
            "Step#57000 CNN update\n",
            "Step#58000 CNN update\n",
            "Step#59000 CNN update\n",
            "Step#60000 CNN update\n",
            "Optimization Finished!\n",
            "CPU times: user 1d 2h 9min 35s, sys: 57min 49s, total: 1d 3h 7min 24s\n",
            "Wall time: 8h 5min 30s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "loss=[]\n",
        "while step * batch_size <= training_epoch*oneiteration+1: # cuantas veces supera la cantidad de interacciones\n",
        "\n",
        "    _,l=sess.run([optimizer,cost_train], feed_dict={keep_prob: dropout})\n",
        "    loss.append(l)\n",
        "    if step%1000==0:\n",
        "        print ('Step#'+str(step)+' CNN update') # loss: '+ str(-l) )\n",
        "    \n",
        "    #loss.append(-l)\n",
        "   # if step % 100000==0: # mostrar algunas veces los resultados...\n",
        "    #    epoch+=1\n",
        "     #   saver.save(sess,'./DVBPR_auc_'+str(K)+'_'+str(step)+'.ckpt')\n",
        "      #  auc_train,auc_test=Evaluation(step)\n",
        "       # print ('Epoch #'+str(epoch)+': test: '+str(auc_test)+' train: '+str(auc_train)+'\\n')\n",
        "        #f.write('Epoch #'+str(epoch)+': test: '+str(auc_test)+' train: '+str(auc_train)+'\\n')\n",
        "        #f.flush()\n",
        "    \n",
        "    step += 1\n",
        "print (\"Optimization Finished!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2V98UnRsin8I",
        "outputId": "0cec3d4b-f552-46d7-8330-31c93620f13b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "...\n",
            "minibatch:  0 / 72\n",
            "minibatch:  1 / 72\n",
            "minibatch:  2 / 72\n",
            "minibatch:  3 / 72\n",
            "minibatch:  4 / 72\n",
            "minibatch:  5 / 72\n",
            "minibatch:  6 / 72\n",
            "minibatch:  7 / 72\n",
            "minibatch:  8 / 72\n",
            "minibatch:  9 / 72\n",
            "minibatch:  10 / 72\n",
            "minibatch:  11 / 72\n",
            "minibatch:  12 / 72\n",
            "minibatch:  13 / 72\n",
            "minibatch:  14 / 72\n",
            "minibatch:  15 / 72\n",
            "minibatch:  16 / 72\n",
            "minibatch:  17 / 72\n",
            "minibatch:  18 / 72\n",
            "minibatch:  19 / 72\n",
            "minibatch:  20 / 72\n",
            "minibatch:  21 / 72\n",
            "minibatch:  22 / 72\n",
            "minibatch:  23 / 72\n",
            "minibatch:  24 / 72\n",
            "minibatch:  25 / 72\n",
            "minibatch:  26 / 72\n",
            "minibatch:  27 / 72\n",
            "minibatch:  28 / 72\n",
            "minibatch:  29 / 72\n",
            "minibatch:  30 / 72\n",
            "minibatch:  31 / 72\n",
            "minibatch:  32 / 72\n",
            "minibatch:  33 / 72\n",
            "minibatch:  34 / 72\n",
            "minibatch:  35 / 72\n",
            "minibatch:  36 / 72\n",
            "minibatch:  37 / 72\n",
            "minibatch:  38 / 72\n",
            "minibatch:  39 / 72\n",
            "minibatch:  40 / 72\n",
            "minibatch:  41 / 72\n",
            "minibatch:  42 / 72\n",
            "minibatch:  43 / 72\n",
            "minibatch:  44 / 72\n",
            "minibatch:  45 / 72\n",
            "minibatch:  46 / 72\n",
            "minibatch:  47 / 72\n",
            "minibatch:  48 / 72\n",
            "minibatch:  49 / 72\n",
            "minibatch:  50 / 72\n",
            "minibatch:  51 / 72\n",
            "minibatch:  52 / 72\n",
            "minibatch:  53 / 72\n",
            "minibatch:  54 / 72\n",
            "minibatch:  55 / 72\n",
            "minibatch:  56 / 72\n",
            "minibatch:  57 / 72\n",
            "minibatch:  58 / 72\n",
            "minibatch:  59 / 72\n",
            "minibatch:  60 / 72\n",
            "minibatch:  61 / 72\n",
            "minibatch:  62 / 72\n",
            "minibatch:  63 / 72\n",
            "minibatch:  64 / 72\n",
            "minibatch:  65 / 72\n",
            "minibatch:  66 / 72\n",
            "minibatch:  67 / 72\n",
            "minibatch:  68 / 72\n",
            "minibatch:  69 / 72\n",
            "minibatch:  70 / 72\n",
            "minibatch:  71 / 72\n",
            "export finised! lei las imagenes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc train:  0.0  auc test:  0.0\n"
          ]
        }
      ],
      "source": [
        "auc_train,auc_test=Evaluation(step)\n",
        "print(\"auc train: \", auc_train,\" auc test: \", auc_test)\n",
        "np.save(workdir+\"resultado.npy\", [auc_train,auc_test])\n",
        "np.save(workdir+\"perdida.npy\",loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVRUz_IoS2xc"
      },
      "outputs": [],
      "source": [
        "loss=np.load(workdir+\"perdida.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7ze1G0IhTRVz",
        "outputId": "e6d6b127-71e8-4382-c309-a531bc13da41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fdd6bce8ed0>]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(len(loss)), loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk5akIP4Td_H"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DVBPR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}