{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"irgan_visual_normal.ipynb","provenance":[],"collapsed_sections":["oz0bbxx-tsKB"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"296.962px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"e9ysjia76BOp"},"source":["# IRGAN"]},{"cell_type":"markdown","metadata":{"id":"JeR_hmKqpnAB"},"source":["Codigo:\n","\n","https://github.com/geek-ai/irgan\n","\n","paper: \n","\n","https://arxiv.org/pdf/1705.10513.pdf"]},{"cell_type":"markdown","metadata":{"id":"7T9tLDtVBlgX"},"source":["Una GAN discreta (como SeqGan) pero que el generador es modelado como un politica de aprendizaje reforzado para seleccionar el documento candidato $d$ en el estado dado la query $q_n$, y una metrica de relevancia $r$ que es entrenado via una politica de gradientes"]},{"cell_type":"markdown","metadata":{"id":"oREzkvuF6DhH"},"source":["Quieren poner enfoque en el entrenamiento adversario, osea usan modelos simples e iguales para D y G"]},{"cell_type":"markdown","metadata":{"id":"18oHp-BWc4Gw"},"source":["El módulo pickle implementa un algoritmo para convertir un objeto Python arbitrario en una serie de bytes. Este proceso también se llama serializar \"el objeto\". El flujo de bytes que representa el objeto se puede transmitir o almacenar y luego reconstruir para crear un nuevo objeto con las mismas características.\n","\n","El módulo cPickle implementa el mismo algoritmo, en C en lugar de Python. Es muchas veces más rápido que la implementación de Python, pero no permite al usuario crear una subclase de Pickle. Si la subclasificación no es importante para su uso, probablemente desee utilizar cPickle."]},{"cell_type":"code","metadata":{"id":"WZmLNRllc5yX","executionInfo":{"status":"ok","timestamp":1638745791668,"user_tz":180,"elapsed":4145,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["import _pickle as cPickle #guarda el modelo..\n","from IPython.display import Latex\n","import tensorflow as tf\n","import numpy as np\n","import multiprocessing\n","import pandas as pd \n","import random\n","import pickle\n","\n","cores = multiprocessing.cpu_count()\n","random.seed(0)\n","\n","\n","import matplotlib.pyplot as plt\n","import heapq\n","tf.compat.v1.disable_eager_execution()"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wa37Wu_tmZ0Q"},"source":["## Discriminativo DNS"]},{"cell_type":"code","metadata":{"id":"xkx5B9xJciJ6","executionInfo":{"status":"ok","timestamp":1638750008895,"user_tz":180,"elapsed":559,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["\n","class DIS():\n","    def __init__(self, itemNum, userNum, emb_dim,visual_matrix, visual_emb, lamda, param=None, initdelta=0.05, learning_rate=0.05,imageFeatureDim= 4096):\n","        self.itemNum = itemNum\n","        self.userNum = userNum\n","        self.emb_dim = emb_dim\n","        self.lamda = lamda  # regularization parameters\n","        self.param = param\n","        self.visual_I = visual_matrix #preentrenada no aprendible\n","        self.k2 = visual_emb\n","        self.initdelta = initdelta\n","        self.learning_rate = learning_rate\n","        self.imageFeatureDim= imageFeatureDim\n","        self.d_params = []\n","\n","        with tf.compat.v1.compat.v1.variable_scope('discriminator'):\n","            if self.param is None: #Si no hay param -> inicializacion aleatoria\n","                self.user_embeddings = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.userNum, self.emb_dim], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                self.item_embeddings = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.itemNum, self.emb_dim], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                self.item_bias = tf.compat.v1.Variable(tf.compat.v1.zeros([self.itemNum]))\n","                #####################################\n","                self.visual_U = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.userNum, self.k2], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                #E\n","                self.itemEmb_W = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.imageFeatureDim,self.k2], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                #beta\n","                self.visual_item_bias = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.itemNum,self.imageFeatureDim], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","\n","                ###################################################\n","            else: #lee los parametros del archivo\n","                self.user_embeddings = tf.compat.v1.Variable(self.param[0])\n","                self.item_embeddings = tf.compat.v1.Variable(self.param[1])\n","                self.item_bias = tf.compat.v1.Variable(self.param[2])\n","                #######################################\n","                self.visual_U = tf.compat.v1.Variable(self.param[3])\n","                self.itemEmb_W = tf.compat.v1.Variable(self.param[4])\n","                self.visual_item_bias = tf.compat.v1.Variable(self.param[5])\n","                ###########################\n","           \n","            self.d_params = [self.user_embeddings, self.item_embeddings, self.item_bias,  self.visual_U, self.itemEmb_W, self.visual_item_bias ]\n","        \n","        # placeholder definition\n","        self.u = tf.compat.v1.placeholder(tf.compat.v1.int32)\n","        self.pos = tf.compat.v1.placeholder(tf.compat.v1.int32)\n","        self.neg = tf.compat.v1.placeholder(tf.compat.v1.int32)\n","\n","        self.u_embedding = tf.compat.v1.nn.embedding_lookup(self.user_embeddings, self.u)\n","        self.pos_embedding = tf.compat.v1.nn.embedding_lookup(self.item_embeddings, self.pos)\n","        self.pos_bias = tf.compat.v1.gather(self.item_bias, self.pos)\n","        self.neg_embedding = tf.compat.v1.nn.embedding_lookup(self.item_embeddings, self.neg)\n","        self.neg_bias = tf.compat.v1.gather(self.item_bias, self.neg)\n","\n","\n","        ##################################################################################\n","\n","        self.visual_U_vector = tf.compat.v1.nn.embedding_lookup(self.visual_U, self.u)\n","        self.visual_I_matrix_pos = tf.compat.v1.nn.embedding_lookup(self.visual_I, self.pos) #[1,4096]\n","        self.visual_I_matrix_neg = tf.compat.v1.nn.embedding_lookup(self.visual_I, self.neg)\n","        self.visual_pos_bias = tf.compat.v1.gather(self.visual_item_bias, self.pos) #[1,4096]\n","        self.visual_neg_bias = tf.compat.v1.gather(self.visual_item_bias, self.neg)\n","\n","       ##################\n","\n","        self.Ef_pos= tf.matmul( self.visual_I_matrix_pos,self.itemEmb_W) #f_i x E= [1,4096]x[4096,k2]= [1,k2]\n","        self.Ef_neg= tf.matmul(self.visual_I_matrix_neg,self.itemEmb_W) \n","        self.Ef= tf.compat.v1.matmul(self.itemEmb_W,self.visual_I,transpose_a=True,transpose_b=True ) #E^T x f^T =  [k2,4096]x[4096,#I] = [k2,#I]\n","        self.bf_pos=tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_I_matrix_pos, self.visual_pos_bias),1)#[1,4096]x[1,4096]\n","        self.bf_neg=  tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_I_matrix_neg, self.visual_neg_bias),1)\n","          \n","        \n","        ##################\n","        \n","        self.pre_logits = tf.compat.v1.sigmoid(\n","            tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.u_embedding, self.pos_embedding - self.neg_embedding),1) # [1,k]x[1,k] multuply es element wise, reduce sum sum, osea producto punto.\n","             + self.pos_bias - self.neg_bias\n","             +  tf.compat.v1.reduce_sum( tf.compat.v1.multiply(self.visual_U_vector,self.Ef_pos- self.Ef_neg ) ,1 )  # [1,k2]x[1,k2]\n","             +self.bf_pos- self.bf_neg \n","                          ) \n","             \n","        \n"," \n","        self.reg= self.lamda * (\n","            tf.compat.v1.nn.l2_loss(self.u_embedding) +\n","            tf.compat.v1.nn.l2_loss(self.pos_embedding) +\n","            tf.compat.v1.nn.l2_loss(self.pos_bias) +\n","            tf.compat.v1.nn.l2_loss(self.neg_embedding) +\n","            tf.compat.v1.nn.l2_loss(self.neg_bias)+\n","            tf.compat.v1.nn.l2_loss(self.visual_U_vector) +\n","            tf.compat.v1.nn.l2_loss(self.itemEmb_W) +\n","            tf.compat.v1.nn.l2_loss(self.visual_neg_bias) +\n","            tf.compat.v1.nn.l2_loss(self.visual_pos_bias)\n","            )\n","\n","        self.pre_loss = -tf.compat.v1.reduce_mean(tf.compat.v1.log(self.pre_logits)) + self.reg\n","        d_opt = tf.compat.v1.train.GradientDescentOptimizer(self.learning_rate)\n","        self.d_updates = d_opt.minimize(self.pre_loss, var_list=self.d_params)\n","\n","        # for test stage, self.u: [batch_size]\n","        \n","                          # uxI= [batch_size,k]x[k,#I]=[batch_size,#I]                                                     # b_i= [1, #I]        # [batch_size, k2]x[k2, #I]  = [bact_size,#I]                                             #beta elementwise f = [#,4096]elementwise[#I,4096]= [1, #I]\n","        self.all_rating = tf.compat.v1.matmul(self.u_embedding, self.item_embeddings, transpose_a=False,transpose_b=True) + self.item_bias + tf.compat.v1.matmul(self.visual_U_vector, self.Ef, transpose_a=False, transpose_b=False) +  tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_item_bias , self.visual_I),1)                    \n","\n","        #self.all_logits = tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.u_embedding, self.item_embeddings), 1) + self.item_bias\n","        # for dns sample\n","        #esto da muy grande\n","                                                                        # [1,k]x[#I,k] = [1,#I]                                 #[1, #I]                                                      #[1,k2]x[#I,k2]=[1,#I]\n","        self.dns_rating = tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.u_embedding, self.item_embeddings), 1) + self.item_bias + tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_U_vector, tf.transpose(self.Ef) ), 1) + tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_item_bias , self.visual_I),1)  \n","\n","    def save_model(self, sess, filename):\n","        param = sess.run(self.d_params)\n","        cPickle.dump(param, open(filename, 'wb'))  #antes w"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oz0bbxx-tsKB"},"source":["## utils.py"]},{"cell_type":"code","metadata":{"id":"xfkSKD5CtwxK","executionInfo":{"status":"ok","timestamp":1638745792014,"user_tz":180,"elapsed":6,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["import linecache\n","import numpy as np\n","\n","\n","def file_len(fname):\n","    with open(fname) as f:\n","        for i, l in enumerate(f):\n","            pass\n","    return i + 1\n","\n","\n","# Get batch data from training set\n","def get_batch_data(file, index, size):  # 1,5->1,2,3,4,5\n","    user = []\n","    item = []\n","    label = []\n","    for i in range(index, index + size):\n","        line = linecache.getline(file, i)\n","        line = line.strip()\n","        line = line.split()\n","        user.append(int(line[0]))\n","        user.append(int(line[0]))\n","        item.append(int(line[1]))\n","        item.append(int(line[2]))\n","        label.append(1.)\n","        label.append(0.)\n","    return user, item, label\n","\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PjnuefL1mdUU"},"source":["## Generador"]},{"cell_type":"code","metadata":{"id":"jEM2J1CTmhOn","executionInfo":{"status":"ok","timestamp":1638751423394,"user_tz":180,"elapsed":210,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["class GEN():\n","    def __init__(self, itemNum, userNum, emb_dim, visual_matrix, visual_emb, lamda, param=None, initdelta=0.05, learning_rate=0.05,imageFeatureDim= 4096):\n","        self.itemNum = itemNum\n","        self.userNum = userNum\n","        self.emb_dim = emb_dim\n","        self.lamda = lamda  # regularization parameters\n","        self.param = param\n","        self.initdelta = initdelta\n","        self.learning_rate = learning_rate\n","        self.g_params = []\n","        self.visual_I = visual_matrix #preentrenada no aprendible\n","        self.k2 = visual_emb\n","        self.imageFeatureDim= imageFeatureDim\n","\n","        with tf.compat.v1.variable_scope('generator'):\n","            if self.param == None: #inicialización de representaciones\n","                self.user_embeddings = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.userNum, self.emb_dim], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                self.item_embeddings = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.itemNum, self.emb_dim], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                self.item_bias = tf.compat.v1.Variable(tf.compat.v1.zeros([self.itemNum]))\n","                #####################################\n","                self.visual_U = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.userNum, self.k2], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                #E\n","                self.itemEmb_W = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.imageFeatureDim,self.k2], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                #beta\n","                self.visual_item_bias = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.itemNum,self.imageFeatureDim], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","\n","                ###################################################\n","\n","\n","            else:\n","                self.user_embeddings = tf.compat.v1.Variable(self.param[0])\n","                self.item_embeddings = tf.compat.v1.Variable(self.param[1])\n","                self.item_bias = tf.compat.v1.Variable(param[2])\n","                                #######################################\n","                self.visual_U = tf.compat.v1.Variable(self.param[3])\n","                self.itemEmb_W = tf.compat.v1.Variable(self.param[4])\n","                self.visual_item_bias = tf.compat.v1.Variable(self.param[5])\n","                ###########################\n","\n","            self.g_params = [self.user_embeddings, self.item_embeddings, self.item_bias,self.visual_U, self.itemEmb_W, self.visual_item_bias ]\n","\n","        self.u = tf.compat.v1.placeholder(tf.compat.v1.int32)\n","        self.i = tf.compat.v1.placeholder(tf.compat.v1.int32)\n","        self.reward = tf.compat.v1.placeholder(tf.compat.v1.float32)\n","\n","        self.u_embedding = tf.compat.v1.nn.embedding_lookup(self.user_embeddings, self.u)\n","        self.i_embedding = tf.compat.v1.nn.embedding_lookup(self.item_embeddings, self.i)\n","        self.i_bias = tf.compat.v1.gather(self.item_bias, self.i)\n","\n","\n","        ##################################################################################\n","\n","        self.visual_U_vector = tf.compat.v1.nn.embedding_lookup(self.visual_U, self.u)\n","        self.visual_I_matrix_i= tf.compat.v1.nn.embedding_lookup(self.visual_I, self.i) #[1,4096]\n","        self.visual_bias_i = tf.compat.v1.gather(self.visual_item_bias, self.i) #[1,4096]\n","\n","       ##################\n","\n","        self.Ef_i= tf.matmul( self.visual_I_matrix_i,self.itemEmb_W) #f_i x E= [1,4096]x[4096,k2]= [1,k2]\n","        self.Ef= tf.compat.v1.matmul(self.itemEmb_W,self.visual_I,transpose_a=True,transpose_b=True ) #E^T x f^T =  [k2,4096]x[4096,#I] = [k2,#I]\n","        self.bf_i=tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_I_matrix_i, self.visual_bias_i),1)#[1,4096]x[1,4096]\n","          \n","        \n","        ##################\n","                                                                                                           \n","                                                                        #[1,k]x[#I,k]                                   #[1,#I]                                # [1,k2]x[1,k2]\n","        self.all_logits = tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.u_embedding, self.item_embeddings), 1) + self.item_bias +  tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_U_vector, tf.transpose(self.Ef) ), 1) + tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_item_bias , self.visual_I),1)  \n","\n","        self.i_prob = tf.compat.v1.gather(\n","            tf.compat.v1.reshape(tf.compat.v1.nn.softmax(tf.compat.v1.reshape(self.all_logits, [1, -1])), [-1]),\n","            self.i)\n","\n","        self.reg= self.lamda * (tf.compat.v1.nn.l2_loss(self.u_embedding) + tf.compat.v1.nn.l2_loss(self.i_embedding) + tf.compat.v1.nn.l2_loss(self.i_bias)+\n","                                 tf.compat.v1.nn.l2_loss(self.visual_U_vector) +tf.compat.v1.nn.l2_loss(self.itemEmb_W) +tf.compat.v1.nn.l2_loss(self.visual_bias_i) )\n","        \n","        self.gan_loss = -tf.compat.v1.reduce_mean(tf.compat.v1.log(self.i_prob) * self.reward) + self.reg\n","\n","        g_opt = tf.compat.v1.train.GradientDescentOptimizer(self.learning_rate)\n","\n","        self.gan_updates = g_opt.minimize(self.gan_loss, var_list=self.g_params)\n","\n","        # for test stage, self.u: [batch_size]\n","        self.all_rating = tf.compat.v1.matmul(self.u_embedding, self.item_embeddings, transpose_a=False,\n","                                    transpose_b=True) + self.item_bias + tf.compat.v1.matmul(self.visual_U_vector, self.Ef, transpose_a=False, transpose_b=False) +  tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_item_bias , self.visual_I),1) \n","\n","    def save_model(self, sess, filename):\n","        param = sess.run(self.g_params)\n","        cPickle.dump(param, open(filename, 'wb')) #mismo cambio"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EzgYVrjhtGBa"},"source":["## Discriminador"]},{"cell_type":"markdown","metadata":{"id":"2Y1XtLZr2Lzr"},"source":["$f_{\\phi} (q,d)= s_{\\phi} (q,d)= s(u,i)= b_i + v_u^Tv_i$\n","\n","Máquina de factorización sencilla\n","\n","Su labor es distinguir (clasificar) si el documento $d$ es relevante (real, etiqueta=1, ejemplo positivo) para la consulta $q$. Estimando la probabilidad:\n","\n","$D(d|q)= \\sigma (f_{\\phi} (q,d))= \\dfrac{exp(f_{\\phi} (q,d))}{1+ exp(f_{\\phi} (q,d))} $\n","\n","Su objetivo entonces es maximiza la log verosimititud de distrinción entre documentos verdaderos y generados:\n","\n","$\\phi^{*}=\\arg \\max _{\\phi} \\sum_{n=1}^{N}\\left(\\mathbb{E}_{d \\sim p_{\\text {true }}\\left(d \\mid q_{n}, r\\right)}\\left[\\log \\left(\\sigma\\left(f_{\\phi}\\left(d, q_{n}\\right)\\right)\\right]+\\right.\\right.$\n","$\\left.\\mathbb{E}_{d \\sim p_{\\theta^{*}}\\left(d \\mid q_{n}, r\\right)}\\left[\\log \\left(1-\\sigma\\left(f_{\\phi}\\left(d, q_{n}\\right)\\right)\\right)\\right]\\right)$\n","\n","Modelo generativo actual fijo"]},{"cell_type":"code","metadata":{"id":"QhMzSMIttFGV","executionInfo":{"status":"ok","timestamp":1638751425714,"user_tz":180,"elapsed":239,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["class DIS():\n","    def __init__(self, itemNum, userNum, emb_dim, visual_matrix, visual_emb,lamda, param=None, initdelta=0.05, learning_rate=0.05,imageFeatureDim=4096):\n","        self.itemNum = itemNum\n","        self.userNum = userNum\n","        self.emb_dim = emb_dim\n","        self.lamda = lamda  # regularization parameters\n","        self.param = param\n","        self.initdelta = initdelta\n","        self.learning_rate = learning_rate\n","        self.d_params = []\n","        self.visual_I = visual_matrix #preentrenada no aprendible\n","        self.k2 = visual_emb\n","        self.imageFeatureDim= imageFeatureDim\n","\n","        with tf.compat.v1.variable_scope('discriminator'):\n","          #inicializacion\n","            if self.param == None:\n","                self.user_embeddings = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.userNum, self.emb_dim], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                self.item_embeddings = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.itemNum, self.emb_dim], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                self.item_bias = tf.compat.v1.Variable(tf.compat.v1.zeros([self.itemNum]))\n","                #####################################\n","                self.visual_U = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.userNum, self.k2], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                #E\n","                self.itemEmb_W = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.imageFeatureDim,self.k2], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","                #beta\n","                self.visual_item_bias = tf.compat.v1.Variable(\n","                    tf.compat.v1.random_uniform([self.itemNum,self.imageFeatureDim], minval=-self.initdelta, maxval=self.initdelta,\n","                                      dtype=tf.compat.v1.float32))\n","\n","                ###################################################\n","\n","\n","            else:\n","                self.user_embeddings = tf.compat.v1.Variable(self.param[0])\n","                self.item_embeddings = tf.compat.v1.Variable(self.param[1])\n","                self.item_bias = tf.compat.v1.Variable(self.param[2])\n","                #######################################\n","                self.visual_U = tf.compat.v1.Variable(self.param[3])\n","                self.itemEmb_W = tf.compat.v1.Variable(self.param[4])\n","                self.visual_item_bias = tf.compat.v1.Variable(self.param[5])\n","                ###########################\n","\n","        self.d_params = [self.user_embeddings, self.item_embeddings, self.item_bias,self.visual_U, self.itemEmb_W, self.visual_item_bias ]\n","\n","        # placeholder definition\n","        self.u = tf.compat.v1.placeholder(tf.compat.v1.int32)\n","        self.i = tf.compat.v1.placeholder(tf.compat.v1.int32)\n","        self.label = tf.compat.v1.placeholder(tf.compat.v1.float32)\n","        #indexaciones\n","        #V_u\n","        self.u_embedding = tf.compat.v1.nn.embedding_lookup(self.user_embeddings, self.u)\n","        #V_i\n","        self.i_embedding = tf.compat.v1.nn.embedding_lookup(self.item_embeddings, self.i)\n","        #b_i\n","        self.i_bias = tf.compat.v1.gather(self.item_bias, self.i)\n","\n","\n","        ##################################################################################\n","\n","        self.visual_U_vector = tf.compat.v1.nn.embedding_lookup(self.visual_U, self.u)\n","        self.visual_I_matrix_i= tf.compat.v1.nn.embedding_lookup(self.visual_I, self.i) #[1,4096]\n","        self.visual_bias_i = tf.compat.v1.gather(self.visual_item_bias, self.i) #[1,4096]\n","\n","       ##################\n","        self.Ef_i= tf.matmul( self.visual_I_matrix_i,self.itemEmb_W) #f_i x E= [1,4096]x[4096,k2]= [1,k2]\n","        self.Ef= tf.compat.v1.matmul(self.itemEmb_W,self.visual_I,transpose_a=True,transpose_b=True ) #E^T x f^T =  [k2,4096]x[4096,#I] = [k2,#I]\n","        self.bf_i=tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_I_matrix_i, self.visual_bias_i),1)#[1,4096]x[1,4096]\n","          \n","        \n","        ##################\n","\n","        #b_i+vu*v_i\n","        self.pre_logits = tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.u_embedding, self.i_embedding), 1) + self.i_bias + tf.compat.v1.reduce_sum( tf.compat.v1.multiply(self.visual_U_vector,self.Ef_i ) ,1 ) + self.bf_i\n","        #sigmoide cross entropy con regularización l2 \n","        self.reg= self.lamda * (\n","            tf.compat.v1.nn.l2_loss(self.u_embedding) + tf.compat.v1.nn.l2_loss(self.i_embedding) + tf.compat.v1.nn.l2_loss(self.i_bias)+\n","                                 tf.compat.v1.nn.l2_loss(self.visual_U_vector) +tf.compat.v1.nn.l2_loss(self.itemEmb_W) +tf.compat.v1.nn.l2_loss(self.visual_bias_i) )\n","        \n","        self.pre_loss = tf.compat.v1.nn.sigmoid_cross_entropy_with_logits(labels=self.label,\n","                                                                logits=self.pre_logits) + self.reg\n","        #SGD\n","        d_opt = tf.compat.v1.train.GradientDescentOptimizer(self.learning_rate)\n","        self.d_updates = d_opt.minimize(self.pre_loss, var_list=self.d_params)\n","        #Recompensa: \n","        #b_i+vu*v_i\n","        self.reward_logits = tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.u_embedding, self.i_embedding),\n","                                           1) + self.i_bias +  tf.compat.v1.reduce_sum( tf.compat.v1.multiply(self.visual_U_vector,self.Ef_i ) ,1 ) + self.bf_i\n","        #2sig(f)-1\n","        self.reward = 2 * (tf.compat.v1.sigmoid(self.reward_logits) - 0.5)\n","\n","        # for test stage, self.u: [batch_size]\n","        self.all_rating = tf.compat.v1.matmul(self.u_embedding, self.item_embeddings, transpose_a=False,\n","                                    transpose_b=True) + self.item_bias + tf.compat.v1.matmul(self.visual_U_vector, self.Ef, transpose_a=False, transpose_b=False) +  tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_item_bias , self.visual_I),1) \n","\n","        #1 usuario todos los items.\n","        \n","        self.all_logits = tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.u_embedding, self.item_embeddings), 1) + self.item_bias +  tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_U_vector, tf.transpose(self.Ef) ), 1) + tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_item_bias , self.visual_I),1)  \n","        \n","        #self.NLL = -tf.compat.v1.reduce_mean(tf.compat.v1.log(\n","            #tf.compat.v1.gather(tf.compat.v1.reshape(tf.compat.v1.nn.softmax(tf.compat.v1.reshape(self.all_logits, [1, -1])), [-1]), self.i)))\n","        # for dns sample\n","         \n","        self.dns_rating = tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.u_embedding, self.item_embeddings), 1) + self.item_bias + tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_U_vector, tf.transpose(self.Ef) ), 1) + tf.compat.v1.reduce_sum(tf.compat.v1.multiply(self.visual_item_bias , self.visual_I),1) \n","\n","    def save_model(self, sess, filename):\n","        param = sess.run(self.d_params)\n","        cPickle.dump(param, open(filename, 'w'))"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iex1cUN48yNZ"},"source":["# Adaptación de IRGAN"]},{"cell_type":"markdown","metadata":{"id":"Rfo9HdFNyRa6"},"source":["## Lectura Amazon "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-Rey0DTyRa6","executionInfo":{"status":"ok","timestamp":1638745883972,"user_tz":180,"elapsed":21229,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"fb958d21-6e77-459e-ff71-ea3b5b606835"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#workdir = '/content/drive/MyDrive/dataset_ml/amazon_men_actualizado/' \n","workdir = '/content/drive/MyDrive/dataset_ml/women/' \n","\n","usuarios_train = np.load(workdir+'dic_train_women.npy',allow_pickle='TRUE')\n","usuarios_train=list(usuarios_train.reshape(-1,1))[0][0]\n","usuarios_test = np.load(workdir+'dic_test_women.npy',allow_pickle='TRUE')\n","usuarios_test=list(usuarios_test.reshape(-1,1))[0][0]\n","DIS_TRAIN_FILE =workdir+ \"dis-train.txt\"\n","DIS_MODEL_FILE =   workdir+\"model_dns_IRGANvisual.pkl\" #rutaaaa"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"GfCSPCJ-yRa6","executionInfo":{"status":"ok","timestamp":1638745895965,"user_tz":180,"elapsed":1691,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["dic_feautures = np.load(workdir+'features_women_effnet.npy',allow_pickle='TRUE')\n","dic_feautures=list(dic_feautures.reshape(-1,1))[0][0]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"4wKFa7dUyRa7","executionInfo":{"status":"ok","timestamp":1638745899056,"user_tz":180,"elapsed":190,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["#########################################################################################\n","# Hyper-parameters\n","#########################################################################################\n","EMB_DIM = 10\n","K2=500\n","DNS_K = 5"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"BHYsg7rQyRa7","executionInfo":{"status":"ok","timestamp":1638745901618,"user_tz":180,"elapsed":801,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["user_pos_test = {}\n","user_pos_train= {}\n","c_t=0\n","all_items= []\n","\n","\n","for u in usuarios_train.keys():\n","  for item in usuarios_train[u]:\n","    if item[b\"productid\"] not in all_items:\n","      all_items.append(item[b\"productid\"])\n","    \n","    if u not in user_pos_train: #nuevo\n","      user_pos_train[u] = [item[b\"productid\"]]\n","    else: #sino agrego\n","      user_pos_train[u].append(item[b\"productid\"])\n","all_user= list(user_pos_train.keys())\n","\n","for u in usuarios_train.keys():    \n","  item=usuarios_test[u][0]\n","  if item[b\"productid\"] not in all_items:\n","    c_t+=1\n","  else:\n","    user_pos_test[u] = [item[b\"productid\"]]\n","\n","ITEM_NUM=len(all_items)\n","USER_NUM= len(usuarios_train.keys())"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1y3AlUDTyRa7","executionInfo":{"status":"ok","timestamp":1638745902628,"user_tz":180,"elapsed":3,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"0d0e01d9-ae65-424a-aa9f-eb7f60392831"},"source":["print(\"% de items en test que no estan en train: \",c_t/len(all_items)*100)\n","print(\"n item: \", ITEM_NUM, \"n usuarios: \", USER_NUM)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["% de items en test que no estan en train:  2.7743271221532093\n","n item:  7245 n usuarios:  3158\n"]}]},{"cell_type":"code","metadata":{"id":"kOtSW4BvyRa7","executionInfo":{"status":"ok","timestamp":1638745940125,"user_tz":180,"elapsed":36914,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["c=0\n","for i in all_items:\n","  vector= dic_feautures[i]\n","  if c==0:\n","    visual_matrix= vector\n","    c=1\n","  else:\n","    visual_matrix= np.concatenate((visual_matrix, vector),axis=0)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QkeYlTfc2DFO","outputId":"d0adfce8-427f-4d54-a236-e21b4781c88f"},"source":["print(visual_matrix.shape)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(9106, 1536)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPhzAUnEyRa7","outputId":"4203ab38-85f5-4798-d558-813443c29098"},"source":["np.max(visual_matrix)"],"execution_count":null,"outputs":[{"data":{"text/plain":["21.523172"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"SkUTjJ8uyRa7","executionInfo":{"status":"ok","timestamp":1638745940125,"user_tz":180,"elapsed":6,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["visual_matrix= visual_matrix/np.max(visual_matrix)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBwKKVux0l4g"},"source":["## Inicialiazacion DNS"]},{"cell_type":"code","metadata":{"id":"IDimN-f3xfpd","executionInfo":{"status":"ok","timestamp":1638745940126,"user_tz":180,"elapsed":6,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["def generate_dns(sess, model_, filename): #dy\n","    \"\"\"\"\n","    crea tripletas u,i,j con los id originales\n","    \"\"\"\n","    data = []\n","    for u in list(user_pos_train.keys()): #para cada usuario\n","        pos = user_pos_train[u] #lo que consumio\n","        all_rating = sess.run(model_.dns_rating, {model_.u: all_user.index(u)}) #evalua el modelo\n","        all_rating = np.array(all_rating)\n","        neg = []\n","        candidates = list(set(all_items) - set(pos) )#los que no ha consumido\n","\n","        for _ in range(len(pos)): #para cada item\n","            choice = np.random.choice(candidates, DNS_K) #se escogen DN_K aleatoriamente de los candidatos\n","            choice= [list(all_items).index(i) for i in choice]\n","            choice_score = all_rating[choice] # sus rating\n","            neg.append(choice[np.argmax(choice_score)] ) #se escoge el items mas cercanos al gusto de esta muestra aleatoria \n","            #top_10_ind=random.sample(heapq.nlargest(10, range(len(choice_score)), choice_score.take),1)\n","            #neg.append(choice[top_10_ind[0]])\n","        for i in range(len(pos)): #para cada item\n","            data.append( str(all_user.index(u)) + '\\t' + str(list(all_items).index(pos[i]) ) + '\\t' + str(neg[i]) )\n","            \n","    with open(filename, 'w')as fout:\n","        fout.write('\\n'.join(data))\n","\n","\n","\n","def AUC(rating, test_users,dict_tov):\n","  \"\"\"\n","  para cada usuario cuenta cuantos items de una muestra aleatoria tiene rating menor a \n","  al rating del item consumido en test\n","  \"\"\"\n","  ans=0\n","  cc=0\n","  for user in test_users:\n","      user_ind= test_users.index(user)\n","      user_= all_user[user]\n","      if dict_tov[user_][0] in all_items:\n","          item_test= list(all_items).index(dict_tov[user_][0])\n","          cc+=1\n","          items_train= [ list(all_items).index(i) for i in user_pos_train[user_]]  \n","          no_considerar= set(items_train+ [item_test]) \n","          count=0\n","          tmpans=0 \n","          for j in random.sample(range(ITEM_NUM),int(50*(len(no_considerar)-1))): #sample\n","              if j in no_considerar: continue\n","              if rating[user_ind,item_test]>rating[user_ind,j]: tmpans+=1\n","              count+=1\n","\n","          tmpans/=float(count)\n","          ans+=tmpans\n","  \n","  ans/=float(cc)\n","  return ans\n","\n","\n","\n","def simple_test(sess, model, dict_tov): \n","  #Calcula AUC para todos los usuarios comparada con el elemento que quedo en el test set\n","  #dict_tov: test o validacion\n"," test_users=[ all_user.index(i) for i in dict_tov.keys()]\n"," user_batch_rating = sess.run(model.all_rating, {model.u: test_users}) \n"," batch_result= AUC(user_batch_rating,test_users, dict_tov)\n","    \n"," return batch_result"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHTKo43Jxfpd","scrolled":false,"executionInfo":{"status":"ok","timestamp":1638746034840,"user_tz":180,"elapsed":94118,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["tf.compat.v1.reset_default_graph()\n","param = None\n","discriminator = DIS(ITEM_NUM, USER_NUM, EMB_DIM, visual_matrix, K2, lamda=0.001, param=param, initdelta=0.1, learning_rate=0.1, imageFeatureDim=1536) #se llama al discriminador DNS\n","\n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.compat.v1.Session(config=config)\n","sess.run(tf.compat.v1.global_variables_initializer())\n","\n","generate_dns(sess, discriminator, DIS_TRAIN_FILE)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LaqhR-XZ9Q7k","scrolled":false,"executionInfo":{"status":"ok","timestamp":1638746477372,"user_tz":180,"elapsed":442541,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"bada5660-22a6-4218-bfb8-5eadf807ac29"},"source":["dis_log = open(workdir+'dis_log_dns_IRGANvisual.txt', 'w')\n","best_AUC=simple_test(sess, discriminator, user_pos_train)\n","#print(sess.run(discriminator.pre_loss,feed_dict={discriminator.u: [0], discriminator.pos: [1],discriminator.neg: [2]}))\n","#print(\"auc discriminador inicializado random\", best_AUC)\n","losses=[]\n","aucs=[]\n","for epoch in range(3): #80 antes\n","  loss_d_=0\n","  c=0\n","  generate_dns(sess, discriminator, DIS_TRAIN_FILE)  # dynamic negative sample tarda 20 seg\n","  with open(DIS_TRAIN_FILE)as fin:\n","\n","          for line in fin:\n","              line = line.split()\n","              c+=1\n","              u = int(line[0])\n","              i = int(line[1])\n","              j = int(line[2])\n","              #se actualiza el discriminador para la nueva tripleta\n","              _ ,loss= sess.run([discriminator.d_updates, discriminator.pre_loss ],\n","                             feed_dict={discriminator.u: [u], discriminator.pos: [i],\n","                                        discriminator.neg: [j]})\n","            \n","            \n","              #print(line)\n","              #print(loss, \"  :loss\")\n","              #print(sess.run([discriminator.reg, discriminator.pre_logits , discriminator.pre_loss],feed_dict={discriminator.u: [u], discriminator.pos: [i],discriminator.neg: [j]}), \"  :reg , prelogits\")\n","              loss_d_+=loss\n","                \n","  losses.append(loss_d_/c)\n","  AUC_actual = simple_test(sess, discriminator,user_pos_train) #evalua\n","  print (\"epoch \", epoch, \"dis: \", AUC_actual, \"loss: \",loss_d_/c )\n","  aucs.append(AUC_actual)\n","    \n","  if AUC_actual> best_AUC:\n","          print(\"mejore\")\n","          best_AUC = AUC_actual\n","          discriminator.save_model(sess, DIS_MODEL_FILE)\n","  \n","  print (\"best AUC: \", best_AUC)\n","\n","  buf = '\\t'.join([str(AUC_actual)])\n","  dis_log.write(str(epoch) + '\\t' + buf + '\\n')\n","  dis_log.flush()\n","\n","dis_log.close()"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  0 dis:  0.764779754068838 loss:  1.4282277613694447\n","mejore\n","best AUC:  0.764779754068838\n","epoch  1 dis:  0.8300072726597184 loss:  1.4230835418816705\n","mejore\n","best AUC:  0.8300072726597184\n","epoch  2 dis:  0.8832622382101626 loss:  1.3068029426871943\n","mejore\n","best AUC:  0.8832622382101626\n"]}]},{"cell_type":"code","metadata":{"id":"7IkTKkqm4Oow","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638746588589,"user_tz":180,"elapsed":200,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"c272e968-d56c-46e1-b600-2e7192455871"},"source":["losses"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.4282277613694447, 1.4230835418816705, 1.3068029426871943]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"-Z13WUMp4SzP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638746589204,"user_tz":180,"elapsed":289,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"78b20a61-602e-4010-8783-3b5ec443572a"},"source":["aucs"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.764779754068838, 0.8300072726597184, 0.8832622382101626]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXjt11Ec6OOk","executionInfo":{"status":"ok","timestamp":1638746620168,"user_tz":180,"elapsed":5219,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"62c1d513-089d-4cf8-9929-fd320108bf09"},"source":["print(simple_test(sess, discriminator,user_pos_train))\n","print(simple_test(sess, discriminator,user_pos_test))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0.883559359279152\n","0.8249765576322927\n"]}]},{"cell_type":"markdown","metadata":{"id":"rnRscRVjxfph"},"source":["## minmax"]},{"cell_type":"markdown","metadata":{"id":"hf2mwD7WEMQT"},"source":["la regularizacion es crucial"]},{"cell_type":"code","metadata":{"id":"fALaOQpbuvA3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638749859934,"user_tz":180,"elapsed":8853,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"8115efa9-53b9-42e9-92ac-aa0c9ea4bb88"},"source":["BATCH_SIZE = 1000 #16\n","import pickle\n","print (\"load model...\")\n","\n","\n","with open( workdir+ \"model_dns_IRGANvisual.pkl\", 'rb') as f: \n","  param = pickle.load(f,encoding=\"bytes\")\n","\n","generator = GEN(ITEM_NUM, USER_NUM, EMB_DIM, visual_matrix, K2,lamda=0.001, param=param, initdelta=0.1,\n","                    learning_rate=0.01, imageFeatureDim=1536 )\n","\n","discriminator = DIS(ITEM_NUM, USER_NUM, EMB_DIM,visual_matrix, K2, lamda=0.001, param=None, initdelta=0.1,\n","                        learning_rate=0.01, imageFeatureDim=1536) #segundo discriminador (el que no es DNS)\n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.compat.v1.Session(config=config)\n","sess.run(tf.compat.v1.global_variables_initializer())\n","g1= simple_test(sess, generator,user_pos_train)\n","d1=simple_test(sess, discriminator,user_pos_train)\n","print (\"gen \", g1)\n","print (\"dis \", d1)"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["load model...\n","gen  0.8836559087510819\n","dis  0.49604105921020003\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ehT7mMYyGmQx","executionInfo":{"status":"ok","timestamp":1638749867950,"user_tz":180,"elapsed":2654,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"f6ec4703-8ecf-4df3-d83f-45268cd14aae"},"source":["print(simple_test(sess, generator,user_pos_test))"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["0.824455624881288\n"]}]},{"cell_type":"markdown","metadata":{"id":"lYs2IPRUH15o"},"source":["load model...\n","gen  0.9116949460266968\n","dis  0.49850717191236965"]},{"cell_type":"code","metadata":{"id":"nrupOJrIwSze","executionInfo":{"status":"ok","timestamp":1638748433392,"user_tz":180,"elapsed":2,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["\n","def generate_for_d(sess, model, filename):\n","    data = []\n","    for u in user_pos_train: #para cada usario\n","        pos = user_pos_train[u] #sus items \n","        rating = sess.run(model.all_rating, {model.u: [all_user.index(u)]}) #completar la matriz \n","        rating = np.array(rating[0]) #/ 0.2  # Temperature #infla los rating #plotear que pasa con la sigmoide cuando ponemos temperatura\n","        exp_rating = np.exp(rating) \n","        prob = exp_rating / np.sum(exp_rating)\n","        #print(u)\n","        neg = np.random.choice(list(all_items), size=len(pos), p=prob) #muestreo negativo \n","        for i in range(len(pos)):\n","            data.append( str(all_user.index(u)) + '\\t' + str(list(all_items).index(pos[i]) ) + '\\t' + str(list(all_items).index(neg[i])) ) \n","\n","    with open(filename, 'w')as fout:\n","        fout.write('\\n'.join(data))\n","\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"id":"lQemBB4FvZwS","scrolled":false,"executionInfo":{"status":"error","timestamp":1638749707682,"user_tz":180,"elapsed":1274291,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"498b692f-d0c1-4893-976e-df0d65789fc5"},"source":["# minimax training\n","dis_log = open('dis_log.txt', 'w')\n","gen_log = open('gen_log.txt', 'w')\n","loss_d=[]\n","auc_epocs_g=[]\n","auc_epocs_d=[]\n","loss_g=[]\n","for epoch in range(15):#15\n","    print(\"inicia minmax\")\n","    if epoch >= 0:\n","        #entrena D \n","        for d_epoch in range(10):##100 #para el generador fijo, entrena al discriminador\n","           # print(\"empieza a entrenarse el discriminador\")\n","            loss_d_=0\n","            if d_epoch % 5 == 0:\n","                generate_for_d(sess, generator, DIS_TRAIN_FILE) #crea un archivo con las tripletas\n","                #print(\"pase\")\n","                train_size = file_len(DIS_TRAIN_FILE)\n","            index = 1\n","            c=0\n","            while index < train_size-BATCH_SIZE: #hacer minibatch con etiquetado si es ejemplo positivo o negativo\n","                if index + BATCH_SIZE <= train_size + 1:\n","                    input_user, input_item, input_label = get_batch_data(DIS_TRAIN_FILE, index, BATCH_SIZE)\n","                else:\n","                    input_user, input_item, input_label = get_batch_data(DIS_TRAIN_FILE, index,\n","                                                                            train_size - index + 1)\n","                index += BATCH_SIZE\n","               # print(index)\n","                _, loss_dis = sess.run([discriminator.d_updates, discriminator.pre_loss],\n","                                 feed_dict={discriminator.u: input_user, discriminator.i: input_item, discriminator.label: input_label}) #actualizaciones de los embeddings y bias tales que clasifiquen bien\n","                loss_d_+=loss_dis\n","                c+=1\n","            \n","            loss_d.append(loss_d_/c)\n","        \n","            auc_actual = simple_test(sess, discriminator, user_pos_train)\n","            auc_epocs_d.append(auc_actual)\n","            #print (\"epoch \", epoch, \"dis: \", auc_actual)\n","            if auc_actual > best_AUC:\n","                print ('mejore: ', auc_actual)\n","                best_AUC = auc_actual\n","\n","        for g_epoch in range(5):  # 50 #para el discriminador fijo (con pesos actualizados), se entrena el generador\n","            #print(\"empieza a entrenarse el generador\")\n","            c=0\n","            loss_g_=0\n","            for u in user_pos_train: #por cada usuario\n","                sample_lambda = 0 #temperatura\n","                pos = [list(all_items).index(i) for i in user_pos_train[u]] #peliculas relevantes\n","                rating = sess.run(generator.all_logits, {generator.u: all_user.index(u)}) #calcula los ratings para ese usuario\n","                exp_rating = np.exp(rating)\n","                prob = exp_rating / np.sum(exp_rating)  # prob is generator distribution p_\\theta\n","                pn = (1 - sample_lambda) * prob\n","                pn[pos] += sample_lambda * 1.0 / len(pos) #pedirle las prob a lo consumido + 0.2/la cantidad de items consumidos\n","                # Now, pn is the Pn in importance sampling, prob is generator distribution p_\\theta\n","                sample = np.random.choice(np.arange(ITEM_NUM), 2 * len(pos), p=pn) #elige el doble de items c/r a lo consumido\n","                \n","                #               # Get reward and adapt it with importance sampling                #######\n","                reward = sess.run(discriminator.reward, {discriminator.u: all_user.index(u), discriminator.i: sample})\n","                reward = reward * prob[sample] / pn[sample]\n","                ######             # Update G              ####################\n","                _, loss_gen = sess.run([generator.gan_updates, generator.gan_loss],{generator.u: all_user.index(u), generator.i: sample, generator.reward: reward}) #actualiza pesos\n","                c+=1\n","                loss_g_+=loss_gen\n","                \n","            loss_g.append(loss_g_/c)\n","            auc_actual = simple_test(sess, generator, user_pos_train)\n","            auc_epocs_g.append(auc_actual)\n","            print (\"epoch \", epoch, \"gen: \", auc_actual)\n","            buf = '\\t'.join([str(auc_actual) ])\n","            gen_log.write(str(epoch) + '\\t' + buf + '\\n')\n","            gen_log.flush()\n","            if auc_actual > best_AUC:\n","                print ('mejore: ', auc_actual)\n","                best_AUC = auc_actual\n","                generator.save_model(sess, \"gan_generator.pkl\") #se guarda el mejor modelo, la mejor factorización matricial.\n","\n","gen_log.close()\n","dis_log.close()\n","\n"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["inicia minmax\n","epoch  0 gen:  0.8796547223601947\n","epoch  0 gen:  0.8775703254815349\n","epoch  0 gen:  0.8753784363101991\n","epoch  0 gen:  0.8752732094933839\n","epoch  0 gen:  0.8711980267991692\n","inicia minmax\n","epoch  1 gen:  0.8677698594851455\n","epoch  1 gen:  0.8650045408549568\n","epoch  1 gen:  0.8638743273363191\n","epoch  1 gen:  0.8607337345261933\n","epoch  1 gen:  0.8580541032551886\n","inicia minmax\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-9692a5624bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mpn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msample_lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pedirle las prob a lo consumido + 0.2/la cantidad de items consumidos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# Now, pn is the Pn in importance sampling, prob is generator distribution p_\\theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITEM_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#elige el doble de items c/r a lo consumido\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;31m#               # Get reward and adapt it with importance sampling                #######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WKIHKxSOA8JD","executionInfo":{"status":"ok","timestamp":1638749816836,"user_tz":180,"elapsed":10024,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"71b2afda-09d5-4cb1-a78d-0d0b347e7a62"},"source":["print(simple_test(sess, discriminator,user_pos_train))\n","print(simple_test(sess, generator,user_pos_train))\n","print(simple_test(sess, discriminator,user_pos_test))\n","print(simple_test(sess, generator,user_pos_test))\n"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0\n","0.0\n","0.0\n","0.0\n"]}]},{"cell_type":"code","metadata":{"id":"OOdJ5Eje4xlO","colab":{"base_uri":"https://localhost:8080/","height":241},"outputId":"ea215210-77be-48ea-e222-de7be233aab9"},"source":["print(simple_test(sess, discriminator,user_pos_train))\n","print(simple_test(sess, generator,user_pos_train))\n","print(simple_test(sess, discriminator,user_pos_test))\n","print(simple_test(sess, generator,user_pos_test))\n","\n","\n","textfile = open(workdir+\"IRGAN_visual.txt\", \"w\")\n","textfile.write(str(loss_d) + \"\\n\")\n","textfile.write(str(auc_epocs_g) + \"\\n\")\n","textfile.write(str(auc_epocs_d) + \"\\n\")\n","textfile.write(str(loss_g) + \"\\n\")\n","textfile.close()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-1cfc450fd68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_pos_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_pos_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_pos_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_pos_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75HJHjNEfLjU","outputId":"a4eb8daf-6caf-4b7c-dcf3-73010a422d7f"},"source":["with open( workdir+ \"gan_generator.pkl\", 'rb') as f: \n","  param = pickle.load(f,encoding=\"bytes\")\n","\n","generator = GEN(ITEM_NUM, USER_NUM, EMB_DIM, visual_matrix, K2,lamda=0.001, param=param, initdelta=0.1,\n","                    learning_rate=0.01, imageFeatureDim=1536 )\n","textfile = open(workdir+\"IRGAN_visual.txt\", \"w\")\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.compat.v1.Session(config=config)\n","sess.run(tf.compat.v1.global_variables_initializer())\n","\n","\n","print(simple_test(sess, generator,user_pos_train))\n","print(simple_test(sess, generator,user_pos_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8918364826814386\n","0.7962727415096519\n"]}]},{"cell_type":"markdown","metadata":{"id":"IqvinsXfruUV"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"PaK8Nx1oruxQ"},"source":["# boots"]},{"cell_type":"markdown","metadata":{"id":"JZKwLkFuruxR"},"source":["## Inicialiazacion DNS"]},{"cell_type":"code","metadata":{"id":"JYotQYzSsBY5","executionInfo":{"status":"ok","timestamp":1638749988661,"user_tz":180,"elapsed":202,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["DIS_TRAIN_FILE =workdir+ \"dis-train_boots.txt\"\n","DIS_MODEL_FILE =   workdir+\"model_dns_IRGANvisual_boots.pkl\" #rutaaaa"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3TRE2d7ruxR","executionInfo":{"status":"ok","timestamp":1638750011410,"user_tz":180,"elapsed":207,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["\n","\n","\n","def AUC(rating, test_users,dict_tov):\n","  \"\"\"\n","  para cada usuario cuenta cuantos items de una muestra aleatoria tiene rating menor a \n","  al rating del item consumido en test\n","  \"\"\"\n","  ans=0\n","  cc=0\n","  for user in test_users:\n","      user_ind= test_users.index(user)\n","      user_= all_user[user]\n","      if dict_tov[user_][0] in all_items:\n","          item_test= list(all_items).index(dict_tov[user_][0])\n","          cc+=1\n","          items_train= [ list(all_items).index(i) for i in user_pos_train[user_]]  \n","          no_considerar= set(items_train+ [item_test]) \n","          count=0\n","          tmpans=0 \n","          for j in random.sample(range(ITEM_NUM),int(50*(len(no_considerar)-1))): #sample\n","              if j in no_considerar: continue\n","              if rating[user_ind,item_test]>rating[user_ind,j]: tmpans+=1\n","              count+=1\n","\n","          tmpans/=float(count)\n","          ans+=tmpans\n","  \n","  ans/=float(cc)\n","  return ans\n","\n","\n","\n","def simple_test(sess, model, dict_tov): \n","  #Calcula AUC para todos los usuarios comparada con el elemento que quedo en el test set\n","  #dict_tov: test o validacion\n"," test_users=[ all_user.index(i) for i in dict_tov.keys()]\n"," user_batch_rating = sess.run(model.all_rating, {model.u: test_users}) \n"," batch_result= AUC(user_batch_rating,test_users, dict_tov)\n","    \n"," return batch_result"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"5-AUf7FsruxR","executionInfo":{"status":"ok","timestamp":1638750014279,"user_tz":180,"elapsed":1006,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["tf.compat.v1.reset_default_graph()\n","param = None\n","discriminator = DIS(ITEM_NUM, USER_NUM, EMB_DIM, visual_matrix, K2, lamda=0.001, param=param, initdelta=0.1, learning_rate=0.1, imageFeatureDim=1536) #se llama al discriminador DNS\n","\n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.compat.v1.Session(config=config)\n","sess.run(tf.compat.v1.global_variables_initializer())\n","\n","#generate_dns(sess, discriminator, DIS_TRAIN_FILE)"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bneC4z8l8BDA"},"source":["no sirve considerar todos ni tomar el top algo sobre una muestra mas grande"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"scrolled":false,"id":"8pajrsMCruxR","executionInfo":{"status":"ok","timestamp":1638751046943,"user_tz":180,"elapsed":1032455,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"2aaddc89-08d2-46ba-b26a-9fc9da7e871e"},"source":["%%time\n","dis_log = open(workdir+'dis_log_dns_IRGANvisual.txt', 'w')\n","best_AUC=simple_test(sess, discriminator, user_pos_train)\n","#print(sess.run(discriminator.pre_loss,feed_dict={discriminator.u: [0], discriminator.pos: [1],discriminator.neg: [2]}))\n","#print(\"auc discriminador inicializado random\", best_AUC)\n","losses=[]\n","DNS_K= 5\n","aucs=[]\n","for epoch in range(int(3*13000)): \n","        u= np.random.choice(list(user_pos_train.keys()),1)[0]\n","        i = list(all_items).index(np.random.choice(user_pos_train[u],1)[0] ) #lo que consumio\n","        pos = user_pos_train[u]\n","        all_rating = sess.run(discriminator.dns_rating, {discriminator.u: all_user.index(u)}) #evalua el modelo\n","        all_rating = np.array(all_rating)\n","        neg = []\n","        candidates = list(set(all_items) - set(pos) )#los que no ha consumido\n","        \n","        choice = np.random.choice(candidates, DNS_K) #se escogen DN_K aleatoriamente de los candidatos\n","        choice= [list(all_items).index(i) for i in choice]\n","        #choice_score = all_rating[choice] # sus rating\n","        #top_10_ind=random.sample(heapq.nlargest(5, range(len(choice_score)), choice_score.take),1)\n","        #j= top_10_ind[0]\n","        j= np.random.choice(choice,1)[0]\n","        u= all_user.index(u)\n","\n","              #se actualiza el discriminador para la nueva tripleta\n","        _ ,loss= sess.run([discriminator.d_updates, discriminator.pre_loss ],\n","                             feed_dict={discriminator.u: [u], discriminator.pos: [i],\n","                                        discriminator.neg: [j]})\n","                \n","        if epoch%1000==0:\n","          losses.append(loss)\n","          AUC_actual = simple_test(sess, discriminator,user_pos_train) #evalua\n","          print (\"epoch \", epoch, \"dis: \", AUC_actual, \"loss: \",loss )\n","          aucs.append(AUC_actual)\n","            \n","          if AUC_actual> best_AUC:\n","                  print(\"mejore\")\n","                  best_AUC = AUC_actual\n","                  discriminator.save_model(sess, DIS_MODEL_FILE)\n","                  print (\"best AUC: \", best_AUC)\n","                  \n","        buf = '\\t'.join([str(AUC_actual)])\n","        dis_log.write(str(epoch) + '\\t' + buf + '\\n')\n","        dis_log.flush()\n","\n","dis_log.close()"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  0 dis:  0.49978562273966504 loss:  1.8491087\n","epoch  1000 dis:  0.6102390527262765 loss:  1.5134777\n","mejore\n","best AUC:  0.6102390527262765\n","epoch  2000 dis:  0.6663210910302388 loss:  2.0852032\n","mejore\n","best AUC:  0.6663210910302388\n","epoch  3000 dis:  0.6924514945689489 loss:  0.83589\n","mejore\n","best AUC:  0.6924514945689489\n","epoch  4000 dis:  0.716865324146674 loss:  0.6856544\n","mejore\n","best AUC:  0.716865324146674\n","epoch  5000 dis:  0.7346901704662361 loss:  0.62767386\n","mejore\n","best AUC:  0.7346901704662361\n","epoch  6000 dis:  0.7520925370632988 loss:  0.6040004\n","mejore\n","best AUC:  0.7520925370632988\n","epoch  7000 dis:  0.7649362784774805 loss:  1.0281943\n","mejore\n","best AUC:  0.7649362784774805\n","epoch  8000 dis:  0.7770029320759096 loss:  0.67943406\n","mejore\n","best AUC:  0.7770029320759096\n","epoch  9000 dis:  0.7881208322438356 loss:  0.3643375\n","mejore\n","best AUC:  0.7881208322438356\n","epoch  10000 dis:  0.8006839376971457 loss:  2.7564154\n","mejore\n","best AUC:  0.8006839376971457\n","epoch  11000 dis:  0.8117888484130905 loss:  0.3474539\n","mejore\n","best AUC:  0.8117888484130905\n","epoch  12000 dis:  0.8148211278690876 loss:  0.2767629\n","mejore\n","best AUC:  0.8148211278690876\n","epoch  13000 dis:  0.825595435997098 loss:  1.219203\n","mejore\n","best AUC:  0.825595435997098\n","epoch  14000 dis:  0.8292421331470231 loss:  4.197754\n","mejore\n","best AUC:  0.8292421331470231\n","epoch  15000 dis:  0.8337121128312343 loss:  0.2328098\n","mejore\n","best AUC:  0.8337121128312343\n","epoch  16000 dis:  0.8449445237545752 loss:  0.2407467\n","mejore\n","best AUC:  0.8449445237545752\n","epoch  17000 dis:  0.8501942049376153 loss:  0.2199915\n","mejore\n","best AUC:  0.8501942049376153\n","epoch  18000 dis:  0.8547426906805008 loss:  0.24651521\n","mejore\n","best AUC:  0.8547426906805008\n","epoch  19000 dis:  0.8538055889902657 loss:  0.1986577\n","epoch  20000 dis:  0.8577250302806728 loss:  0.33318973\n","mejore\n","best AUC:  0.8577250302806728\n","epoch  21000 dis:  0.8634283584295277 loss:  0.45899272\n","mejore\n","best AUC:  0.8634283584295277\n","epoch  22000 dis:  0.863478193631624 loss:  2.2591767\n","mejore\n","best AUC:  0.863478193631624\n","epoch  23000 dis:  0.864087285590343 loss:  4.809033\n","mejore\n","best AUC:  0.864087285590343\n","epoch  24000 dis:  0.8681606739757116 loss:  0.31434783\n","mejore\n","best AUC:  0.8681606739757116\n","epoch  25000 dis:  0.8720361515315113 loss:  0.18168394\n","mejore\n","best AUC:  0.8720361515315113\n","epoch  26000 dis:  0.875871407596346 loss:  0.1934179\n","mejore\n","best AUC:  0.875871407596346\n","epoch  27000 dis:  0.880826944164397 loss:  0.2549404\n","mejore\n","best AUC:  0.880826944164397\n","epoch  28000 dis:  0.8835586724843774 loss:  0.19380991\n","mejore\n","best AUC:  0.8835586724843774\n","epoch  29000 dis:  0.885776052825408 loss:  0.3059181\n","mejore\n","best AUC:  0.885776052825408\n","epoch  30000 dis:  0.8918159120930047 loss:  0.22944565\n","mejore\n","best AUC:  0.8918159120930047\n","epoch  31000 dis:  0.8887411100277659 loss:  2.8964264\n","epoch  32000 dis:  0.8896473932361595 loss:  0.20521611\n","epoch  33000 dis:  0.8915221315643224 loss:  0.38141525\n","epoch  34000 dis:  0.8932094300459945 loss:  0.16770734\n","mejore\n","best AUC:  0.8932094300459945\n","epoch  35000 dis:  0.8928985098500998 loss:  1.9987175\n","epoch  36000 dis:  0.8988257774680881 loss:  0.22008139\n","mejore\n","best AUC:  0.8988257774680881\n","epoch  37000 dis:  0.8962007352097292 loss:  0.20648883\n","epoch  38000 dis:  0.8985618693148146 loss:  0.16071637\n","CPU times: user 16min 39s, sys: 1min 4s, total: 17min 44s\n","Wall time: 17min 12s\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ry3aQqjZ1aDa"},"source":["10 min"]},{"cell_type":"code","metadata":{"id":"iVI_vMdlMfz0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPHNS7r3ruxR","outputId":"27a2a063-eba6-418b-929d-92a76dbcdaa4"},"source":["losses"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2.1868389,\n"," 1.7881312,\n"," 1.0148097,\n"," 1.2934322,\n"," 1.3698366,\n"," 1.6798588,\n"," 3.745894,\n"," 2.011859,\n"," 1.3152875,\n"," 0.38579193,\n"," 0.3035177,\n"," 0.8363096,\n"," 0.24836853,\n"," 0.50014067,\n"," 0.22480404,\n"," 0.29385698,\n"," 1.4113066,\n"," 0.4110213,\n"," 3.2906075,\n"," 0.22062498,\n"," 0.18669222,\n"," 1.4601772,\n"," 2.6433158,\n"," 0.18913093,\n"," 0.2937286,\n"," 1.140865,\n"," 0.15744506,\n"," 0.46696293,\n"," 0.4191337,\n"," 0.17421812,\n"," 0.16830167,\n"," 0.15166791,\n"," 0.20471117,\n"," 0.22423783,\n"," 0.2820512,\n"," 1.9683537,\n"," 0.4429149,\n"," 0.2817332,\n"," 0.18318751]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pimExmA0ruxR","outputId":"ddcf3c68-7f48-4e28-b366-d647f7b6435e"},"source":["aucs"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5055475002613208,\n"," 0.573546700865084,\n"," 0.6177135844539908,\n"," 0.648715990073503,\n"," 0.6695154125219906,\n"," 0.6923508779450961,\n"," 0.7091820225976351,\n"," 0.724135466595321,\n"," 0.7377152309708979,\n"," 0.7515498174531824,\n"," 0.7617883373702996,\n"," 0.7716213256867186,\n"," 0.782433537687032,\n"," 0.7891710197983616,\n"," 0.7965770845843886,\n"," 0.8008403508377361,\n"," 0.8076128631442999,\n"," 0.8160366252942725,\n"," 0.8223511781043131,\n"," 0.8289267646315571,\n"," 0.8337856408200479,\n"," 0.835255802130257,\n"," 0.8376346481522662,\n"," 0.8391557767122175,\n"," 0.8457001069286695,\n"," 0.8483239256324794,\n"," 0.8526820701767674,\n"," 0.855310869786389,\n"," 0.8582932908571451,\n"," 0.8607883838438585,\n"," 0.8650612406462637,\n"," 0.8656892714128577,\n"," 0.8684307995114273,\n"," 0.8686146193166057,\n"," 0.8681460289209162,\n"," 0.8711450230831335,\n"," 0.875560896347232,\n"," 0.8786237128037755,\n"," 0.8810858812863958]"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"AAGIbMDgruxR"},"source":["## minmax"]},{"cell_type":"markdown","metadata":{"id":"1DVYZKcxruxR"},"source":["la regularizacion es crucial"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylCrkCWDruxR","executionInfo":{"status":"ok","timestamp":1638754868269,"user_tz":180,"elapsed":8613,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"baf574e8-6847-493e-9ed0-07c148127f51"},"source":["BATCH_SIZE = 1000 #16\n","import pickle\n","print (\"load model...\")\n","\n","\n","with open( workdir+ \"model_dns_IRGANvisual.pkl\", 'rb') as f: \n","  param = pickle.load(f,encoding=\"bytes\")\n","\n","generator = GEN(ITEM_NUM, USER_NUM, EMB_DIM, visual_matrix, K2,lamda=0.001, param=param, initdelta=0.1,\n","                    learning_rate=0.01, imageFeatureDim=1536 )\n","\n","discriminator = DIS(ITEM_NUM, USER_NUM, EMB_DIM,visual_matrix, K2, lamda=0.001, param=None, initdelta=0.1,\n","                        learning_rate=0.01, imageFeatureDim=1536) #segundo discriminador (el que no es DNS)\n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.compat.v1.Session(config=config)\n","sess.run(tf.compat.v1.global_variables_initializer())\n","g1= simple_test(sess, generator,user_pos_train)\n","d1=simple_test(sess, discriminator,user_pos_train)\n","print (\"gen \", g1)\n","print (\"dis \", d1)"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["load model...\n","gen  0.8837115158459986\n","dis  0.4954035303385657\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6zqybatpBRW9","executionInfo":{"status":"ok","timestamp":1638754874743,"user_tz":180,"elapsed":5228,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"57ae3d05-436e-412f-ec2d-2b11f01b74be"},"source":["\n","print(simple_test(sess, generator,user_pos_train))\n","\n","print(simple_test(sess, generator,user_pos_test))"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8842785602469558\n","0.8246443062526182\n"]}]},{"cell_type":"code","metadata":{"id":"KC6VhlmlruxR","executionInfo":{"status":"ok","timestamp":1638754874743,"user_tz":180,"elapsed":4,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}}},"source":["\n","def generate_for_d(sess, model, filename):\n","    data = []\n","    for u in user_pos_train: #para cada usario\n","        pos = user_pos_train[u] #sus items \n","        rating = sess.run(model.all_rating, {model.u: [all_user.index(u)]}) #completar la matriz \n","        rating = np.array(rating[0]) #/ 0.2  # Temperature #infla los rating #plotear que pasa con la sigmoide cuando ponemos temperatura\n","        exp_rating = np.exp(rating) \n","        prob = exp_rating / np.sum(exp_rating)\n","        #print(u)\n","        neg = np.random.choice(list(all_items), size=len(pos), p=prob) #muestreo negativo \n","        for i in range(len(pos)):\n","            data.append( str(all_user.index(u)) + '\\t' + str(list(all_items).index(pos[i]) ) + '\\t' + str(list(all_items).index(neg[i])) ) \n","\n","    with open(filename, 'w')as fout:\n","        fout.write('\\n'.join(data))\n","\n"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"scrolled":false,"id":"e-JN8iRGruxR","executionInfo":{"status":"error","timestamp":1638754855295,"user_tz":180,"elapsed":196,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"b99a3623-f1dd-4c21-b8bd-1fce2d355cde"},"source":["# minimax training\n","dis_log = open('dis_log_boots.txt', 'w')\n","gen_log = open('gen_log_boots.txt', 'w')\n","loss_d=[]\n","auc_epocs_g=[]\n","auc_epocs_d=[]\n","loss_g=[]\n","\n","for epoch in range(15):#15\n","    print(\"inicia minmax\")\n","    if epoch >= 0:\n","        #entrena D \n","         for d_epoch in range(10):##100 #para el generador fijo, entrena al discriminador\n","           # print(\"empieza a entrenarse el discriminador\")\n","            loss_d_=0\n","            if d_epoch % 5 == 0:\n","                generate_for_d(sess, generator, DIS_TRAIN_FILE) #crea un archivo con las tripletas\n","                #print(\"pase\")\n","                train_size = file_len(DIS_TRAIN_FILE)\n","            index = 1\n","            c=0\n","            while index < train_size-BATCH_SIZE: #hacer minibatch con etiquetado si es ejemplo positivo o negativo\n","                if index + BATCH_SIZE <= train_size + 1:\n","                    input_user, input_item, input_label = get_batch_data(DIS_TRAIN_FILE, index, BATCH_SIZE)\n","                else:\n","                    input_user, input_item, input_label = get_batch_data(DIS_TRAIN_FILE, index,\n","                                                                            train_size - index + 1)\n","                index += BATCH_SIZE\n","               # print(index)\n","                _, loss_dis = sess.run([discriminator.d_updates, discriminator.pre_loss],\n","                                 feed_dict={discriminator.u: input_user, discriminator.i: input_item, discriminator.label: input_label}) #actualizaciones de los embeddings y bias tales que clasifiquen bien\n","                loss_d_+=loss_dis\n","                c+=1\n","            \n","            loss_d.append(loss_d_/c)\n","            auc_actual = simple_test(sess, discriminator, user_pos_train)\n","            auc_epocs_d.append(auc_actual)\n","            print (\"epoch \", epoch, \"dis: \", loss_d_/c)\n","            if auc_actual > best_AUC:\n","                print ('mejore: ', auc_actual)\n","                best_AUC = auc_actual\n","\n","         for g_epoch in range(5):  #\n","            #print(\"empieza a entrenarse el generador\")\n","            c=0\n","            loss_g_=0\n","            for u in user_pos_train: #por cada usuario #por cada usuario\n","                #u= np.random.choice(list(user_pos_train.keys()),1)[0]\n","                sample_lambda = 0 #temperatura\n","                pos = [list(all_items).index(i) for i in user_pos_train[u]] #peliculas relevantes\n","                rating = sess.run(generator.all_logits, {generator.u: all_user.index(u)}) #calcula los ratings para ese usuario\n","                exp_rating = np.exp(rating)\n","                prob = exp_rating / np.sum(exp_rating)  # prob is generator distribution p_\\theta\n","                pn = (1 - sample_lambda) * prob\n","                pn[pos] += sample_lambda * 1.0 / len(pos) #pedirle las prob a lo consumido + 0.2/la cantidad de items consumidos\n","                # Now, pn is the Pn in importance sampling, prob is generator distribution p_\\theta\n","                sample = np.random.choice(np.arange(ITEM_NUM), 2 * len(pos), p=pn) #elige el doble de items c/r a lo consumido\n","                \n","                #               # Get reward and adapt it with importance sampling                #######\n","                reward = sess.run(discriminator.reward, {discriminator.u: all_user.index(u), discriminator.i: sample})\n","                reward = reward * prob[sample] / pn[sample]\n","                ######             # Update G              ####################\n","                _, loss_gen = sess.run([generator.gan_updates, generator.gan_loss],{generator.u: all_user.index(u), generator.i: sample, generator.reward: reward}) #actualiza pesos\n","                c+=1\n","                loss_g_+=loss_gen\n","                \n","            loss_g.append(loss_g_/c)\n","            auc_actual = simple_test(sess, generator, user_pos_train)\n","            auc_epocs_g.append(auc_actual)\n","            print (\"epoch \", epoch, \"gen: \", auc_actual)\n","            buf = '\\t'.join([str(auc_actual) ])\n","            gen_log.write(str(epoch) + '\\t' + buf + '\\n')\n","            gen_log.flush()\n","            if auc_actual > best_AUC:\n","                print ('mejore: ', auc_actual)\n","                best_AUC = auc_actual\n","                generator.save_model(sess, \"gan_generator_boots.pkl\") #se guarda el mejor modelo, la mejor factorización matricial.\n","\n","            print(simple_test(sess, discriminator,user_pos_train))\n","            print(simple_test(sess, generator,user_pos_train))\n","            print(simple_test(sess, discriminator,user_pos_test))\n","            print(simple_test(sess, generator,user_pos_test))\n","\n","gen_log.close()\n","dis_log.close()\n","\n"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["inicia minmax\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-e3f93821abf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss_d_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0md_epoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mgenerate_for_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIS_TRAIN_FILE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#crea un archivo con las tripletas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0;31m#print(\"pase\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIS_TRAIN_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-44-a0282b1202cb>\u001b[0m in \u001b[0;36mgenerate_for_d\u001b[0;34m(sess, model, filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_rating\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_rating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print(u)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#muestreo negativo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_user\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\t'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\t'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"]}]},{"cell_type":"markdown","metadata":{"id":"qGBoRTVWLN0X"},"source":["18 min"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"384bCOZNruxR","outputId":"441e594a-e966-4edf-8077-bd4a3e6d5a31"},"source":["print(simple_test(sess, discriminator,user_pos_train))\n","print(simple_test(sess, generator,user_pos_train))\n","print(simple_test(sess, discriminator,user_pos_test))\n","print(simple_test(sess, generator,user_pos_test))\n","\n","\n","textfile = open(workdir+\"IRGAN_visual_boots_comoirgannormal.txt\", \"w\")\n","textfile.write(str(loss_d) + \"\\n\")\n","textfile.write(str(auc_epocs_g) + \"\\n\")\n","textfile.write(str(auc_epocs_d) + \"\\n\")\n","textfile.write(str(loss_g) + \"\\n\")\n","textfile.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6171250844856352\n","0.6737021974803182\n","0.5250191288545369\n","0.7675225830890676\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"EezvosxrruxR","executionInfo":{"status":"error","timestamp":1638754830733,"user_tz":180,"elapsed":211,"user":{"displayName":"Mario carlos Mallea ruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14453578379494969160"}},"outputId":"c93b8b61-4d18-4177-ae43-456ce0940e60"},"source":["with open( \"gan_generator_boots.pkl\", 'rb') as f: \n","  param = pickle.load(f,encoding=\"bytes\")\n","\n","generator = GEN(ITEM_NUM, USER_NUM, EMB_DIM, visual_matrix, K2,lamda=0.001, param=param, initdelta=0.1,\n","                    learning_rate=0.01, imageFeatureDim=1536 )\n","textfile = open(workdir+\"IRGAN_visual_boots.txt\", \"w\")\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.compat.v1.Session(config=config)\n","sess.run(tf.compat.v1.global_variables_initializer())\n","\n","\n","print(simple_test(sess, generator,user_pos_train))\n","print(simple_test(sess, generator,user_pos_test))"],"execution_count":46,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-9f70592630ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"gan_generator_boots.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m generator = GEN(ITEM_NUM, USER_NUM, EMB_DIM, visual_matrix, K2,lamda=0.001, param=param, initdelta=0.1,\n\u001b[1;32m      5\u001b[0m                     learning_rate=0.01, imageFeatureDim=1536 )\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gan_generator_boots.pkl'"]}]},{"cell_type":"markdown","metadata":{"id":"fnqc16npKAkl"},"source":["0.9198166097131708\n","\n","0.8090884325775983"]},{"cell_type":"markdown","metadata":{"id":"ghgVQ9D3je-W"},"source":["cuando se calcula normal da:\n","\n","0.9280702236824342\n","0.8085925214610905\n","\n","pero demorando 1h ..... no es significativo el cambio la verdad pero es mas lento"]}]}